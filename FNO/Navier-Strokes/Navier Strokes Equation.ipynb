{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "import utilities3\n",
    "import importlib\n",
    "importlib.reload(utilities3)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complex multiplication\n",
    "def compl_mul3d(a, b):\n",
    "    # (batch, in_channel, x,y,t ), (in_channel, out_channel, x,y,t) -> (batch, out_channel, x,y,t)\n",
    "    op = partial(torch.einsum, \"bixyz,ioxyz->boxyz\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "################################################################\n",
    "# 3d fourier layers\n",
    "################################################################\n",
    "\n",
    "class SpectralConv3d_fast(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2, modes3):\n",
    "        super(SpectralConv3d_fast, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        3D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
    "        self.weights3 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
    "        self.weights4 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, self.modes3, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.rfft(x, 3, normalized=True, onesided=True)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.in_channels, x.size(-3), x.size(-2), x.size(-1)//2 + 1, 2, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2, :self.modes3] = \\\n",
    "            compl_mul3d(x_ft[:, :, :self.modes1, :self.modes2, :self.modes3], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2, :self.modes3] = \\\n",
    "            compl_mul3d(x_ft[:, :, -self.modes1:, :self.modes2, :self.modes3], self.weights2)\n",
    "        out_ft[:, :, :self.modes1, -self.modes2:, :self.modes3] = \\\n",
    "            compl_mul3d(x_ft[:, :, :self.modes1, -self.modes2:, :self.modes3], self.weights3)\n",
    "        out_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3] = \\\n",
    "            compl_mul3d(x_ft[:, :, -self.modes1:, -self.modes2:, :self.modes3], self.weights4)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.irfft(out_ft, 3, normalized=True, onesided=True, signal_sizes=(x.size(-3), x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class SimpleBlock3d(nn.Module):\n",
    "    def __init__(self, modes1, modes2, modes3, width):\n",
    "        super(SimpleBlock3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t). It's a constant function in time, except for the last index.\n",
    "        input shape: (batchsize, x=64, y=64, t=40, c=13)\n",
    "        output: the solution of the next 40 timesteps\n",
    "        output shape: (batchsize, x=64, y=64, t=40, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.modes3 = modes3\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(13, self.width)\n",
    "        # input channel is 12: the solution of the first 10 timesteps + 3 locations (u(1, x, y), ..., u(10, x, y),  x, y, t)\n",
    "\n",
    "\n",
    "        self.conv0 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv1 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv2 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv3 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv4 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv5 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv6 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        self.conv7 = SpectralConv3d_fast(self.width, self.width, self.modes1, self.modes2, self.modes3)\n",
    "        \n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w4 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w5 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w6 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w7 = nn.Conv1d(self.width, self.width, 1)\n",
    "        \n",
    "        self.bn0 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn4 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn5 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn6 = torch.nn.BatchNorm3d(self.width)\n",
    "        self.bn7 = torch.nn.BatchNorm3d(self.width)\n",
    "        \n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y, size_z = x.shape[1], x.shape[2], x.shape[3]\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 4, 1, 2, 3)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn0(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn1(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn2(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn3(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv4(x)\n",
    "        x2 = self.w4(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn4(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv5(x)\n",
    "        x2 = self.w5(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn5(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv6(x)\n",
    "        x2 = self.w6(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn6(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        \n",
    "        x1 = self.conv7(x)\n",
    "        x2 = self.w7(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y, size_z)\n",
    "        x = self.bn7(x1 + x2)\n",
    "               \n",
    "        x = x.permute(0, 2, 3, 4, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net3d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(Net3d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        A wrapper function\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = SimpleBlock3d(modes, modes, modes, width)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1000\n",
    "ntest = 200\n",
    "\n",
    "modes = 4\n",
    "width = 8\n",
    "\n",
    "batch_size = 10\n",
    "batch_size2 = batch_size\n",
    "\n",
    "epochs = 10\n",
    "learning_rate = 0.0025\n",
    "scheduler_step = 100\n",
    "scheduler_gamma = 0.5\n",
    "\n",
    "sub = 1\n",
    "S = 64 // sub\n",
    "T_in = 10\n",
    "T = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = utilities3.MatReader('data/NavierStokes_V1e-5_N1200_T20.mat')\n",
    "train_a = reader.read_field('u')[:ntrain,::sub,::sub,:T_in]\n",
    "train_u = reader.read_field('u')[:ntrain,::sub,::sub,T_in:T+T_in]\n",
    "\n",
    "reader = utilities3.MatReader('data/NavierStokes_V1e-5_N1200_T20.mat')\n",
    "test_a = reader.read_field('u')[-ntest:,::sub,::sub,:T_in]\n",
    "test_u = reader.read_field('u')[-ntest:,::sub,::sub,T_in:T+T_in]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_a is torch.Size([1000, 64, 64, 10]) and the shape of train_u is torch.Size([1000, 64, 64, 10])\n",
      "The shape of test_a is torch.Size([200, 64, 64, 10]) and the shape of test_u is torch.Size([200, 64, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of train_a is {train_a.shape} and the shape of train_u is {train_u.shape}')\n",
    "print(f'The shape of test_a is {test_a.shape} and the shape of test_u is {test_u.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "a_normalizer = utilities3.UnitGaussianNormalizer(train_a)\n",
    "train_a = a_normalizer.encode(train_a)\n",
    "test_a = a_normalizer.encode(test_a)\n",
    "\n",
    "y_normalizer = utilities3.UnitGaussianNormalizer(train_u)\n",
    "train_u = y_normalizer.encode(train_u)\n",
    "\n",
    "train_a = train_a.reshape(ntrain,S,S,1,T_in).repeat([1,1,1,T,1])\n",
    "test_a = test_a.reshape(ntest,S,S,1,T_in).repeat([1,1,1,T,1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_a is torch.Size([1000, 64, 64, 10, 10]) and the shape of test_a is torch.Size([200, 64, 64, 10, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of train_a is {train_a.shape} and the shape of test_a is {test_a.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "gridx = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridx = gridx.reshape(1, S, 1, 1, 1).repeat([1, 1, S, T, 1])\n",
    "gridy = torch.tensor(np.linspace(0, 1, S), dtype=torch.float)\n",
    "gridy = gridy.reshape(1, 1, S, 1, 1).repeat([1, S, 1, T, 1])\n",
    "gridt = torch.tensor(np.linspace(0, 1, T+1)[1:], dtype=torch.float)\n",
    "gridt = gridt.reshape(1, 1, 1, T, 1).repeat([1, S, S, 1, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_a = torch.cat((gridx.repeat([ntrain,1,1,1,1]), gridy.repeat([ntrain,1,1,1,1]),\n",
    "                       gridt.repeat([ntrain,1,1,1,1]), train_a), dim=-1)\n",
    "test_a = torch.cat((gridx.repeat([ntest,1,1,1,1]), gridy.repeat([ntest,1,1,1,1]),\n",
    "                       gridt.repeat([ntest,1,1,1,1]), test_a), dim=-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of train_a is torch.Size([1000, 64, 64, 10, 13]) and the shape of test_a is torch.Size([200, 64, 64, 10, 13])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of train_a is {train_a.shape} and the shape of test_a is {test_a.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(train_a, train_u), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "264241\n"
     ]
    }
   ],
   "source": [
    "model = Net3d(modes, width).cuda()\n",
    "# model = torch.load('model/ns_fourier_V100_N1000_ep100_m8_w20')\n",
    "\n",
    "print(model.count_params())\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=scheduler_step, gamma=scheduler_gamma)\n",
    "\n",
    "\n",
    "myloss = utilities3.LpLoss(size_average=False)\n",
    "y_normalizer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad.LAKES\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:37: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:590.)\n",
      "C:\\Users\\Saad.LAKES\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:47: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:602.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 12.516563900000165 0.4346744956076145 0.40211517190933227 0.32893134117126466\n"
     ]
    }
   ],
   "source": [
    "train_loss =[]\n",
    "test_loss =[]\n",
    "for ep in range(1):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    train_l2 = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out = model(x)\n",
    "\n",
    "        mse = F.mse_loss(out, y, reduction='mean')\n",
    "        # mse.backward()\n",
    "\n",
    "        y = y_normalizer.decode(y)\n",
    "        out = y_normalizer.decode(out)\n",
    "        l2 = myloss(out.view(batch_size, -1), y.view(batch_size, -1))\n",
    "#         print(l2)\n",
    "        l2.backward()\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += mse.item()\n",
    "        train_l2 += l2.item()\n",
    "    train_loss.append(train_l2/ntrain)\n",
    "\n",
    "    scheduler.step()\n",
    "\n",
    "    model.eval()\n",
    "    test_l2 = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x)\n",
    "            out = y_normalizer.decode(out)\n",
    "            test_l2 += myloss(out.view(batch_size, -1), y.view(batch_size, -1)).item()\n",
    "        test_loss.append(test_l2/ntest)\n",
    "\n",
    "    train_mse /= len(train_loader)\n",
    "    train_l2 /= ntrain\n",
    "    test_l2 /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_mse, train_l2, test_l2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(train_loss,'b',label='Training Loss')\n",
    "plt.plot(test_loss,'r',label='Testing Loss')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.zeros(test_u.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(test_a, test_u), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(out)\n",
    "        pred[index] = out\n",
    "\n",
    "        test_l2 += myloss(out.view(1, -1), y.view(1, -1)).item()\n",
    "#         print(index, test_l2)\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of the predictions is torch.Size([200, 64, 64, 10]) and the shape of actual is torch.Size([200, 64, 64, 10])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of the predictions is {pred.shape} and the shape of actual is {test_u.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.subplot(121)\n",
    "plt.imshow(test_u[1,:,:,2],cmap='hot')\n",
    "plt.title('Ground Truth')\n",
    "\n",
    "plt.subplot(122)\n",
    "plt.imshow(pred[1,:,:,2],cmap='hot')\n",
    "plt.title('Prediction Results')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.animation as animation\n",
    "Writer = animation.writers['ffmpeg']\n",
    "writer = Writer(fps=1, metadata=dict(artist='Me'), bitrate=1800)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot(121)\n",
    "ax1= fig.add_subplot(122)\n",
    "ax.title.set_text('Ground Truth')\n",
    "ax1.title.set_text('Prediction Results')\n",
    "# ax1.title('Prediction Results')\n",
    "def plot(i):\n",
    "    data = test_u[0,:,:,i]\n",
    "    pred_data = pred[0,:,:,i]\n",
    "    heatmap = ax.imshow(data,cmap='hot')\n",
    "    heatmap1= ax1.imshow(pred_data,cmap='hot')\n",
    "ani = animation.FuncAnimation(fig,plot,interval=10000000,frames=9)\n",
    "ani.save('NS Results_4layers8nodes.mp4',writer=writer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
