{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.nn.parameter import Parameter\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import operator\n",
    "from functools import reduce\n",
    "from functools import partial\n",
    "\n",
    "from timeit import default_timer\n",
    "import utilities3\n",
    "import importlib\n",
    "importlib.reload(utilities3)\n",
    "\n",
    "torch.manual_seed(0)\n",
    "np.random.seed(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ntrain = 1000\n",
    "ntest = 100\n",
    "\n",
    "batch_size = 20\n",
    "learning_rate = 0.001\n",
    "\n",
    "epochs = 500\n",
    "step_size = 100\n",
    "gamma = 0.5\n",
    "\n",
    "modes = 12\n",
    "width = 32\n",
    "\n",
    "r = 5\n",
    "h = int(((421 - 1)/r) + 1)\n",
    "s = h"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Complex multiplication\n",
    "def compl_mul2d(a, b):\n",
    "    # (batch, in_channel, x,y ), (in_channel, out_channel, x,y) -> (batch, out_channel, x,y)\n",
    "    op = partial(torch.einsum, \"bixy,ioxy->boxy\")\n",
    "    return torch.stack([\n",
    "        op(a[..., 0], b[..., 0]) - op(a[..., 1], b[..., 1]),\n",
    "        op(a[..., 1], b[..., 0]) + op(a[..., 0], b[..., 1])\n",
    "    ], dim=-1)\n",
    "\n",
    "\n",
    "################################################################\n",
    "# fourier layer\n",
    "################################################################\n",
    "class SpectralConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, modes1, modes2):\n",
    "        super(SpectralConv2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        2D Fourier layer. It does FFT, linear transform, and Inverse FFT.    \n",
    "        \"\"\"\n",
    "\n",
    "        self.in_channels = in_channels\n",
    "        self.out_channels = out_channels\n",
    "        self.modes1 = modes1 #Number of Fourier modes to multiply, at most floor(N/2) + 1\n",
    "        self.modes2 = modes2\n",
    "\n",
    "        self.scale = (1 / (in_channels * out_channels))\n",
    "        self.weights1 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
    "        self.weights2 = nn.Parameter(self.scale * torch.rand(in_channels, out_channels, self.modes1, self.modes2, 2))\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        #Compute Fourier coeffcients up to factor of e^(- something constant)\n",
    "        x_ft = torch.rfft(x, 2, normalized=True, onesided=True)\n",
    "\n",
    "        # Multiply relevant Fourier modes\n",
    "        out_ft = torch.zeros(batchsize, self.in_channels,  x.size(-2), x.size(-1)//2 + 1, 2, device=x.device)\n",
    "        out_ft[:, :, :self.modes1, :self.modes2] = \\\n",
    "            compl_mul2d(x_ft[:, :, :self.modes1, :self.modes2], self.weights1)\n",
    "        out_ft[:, :, -self.modes1:, :self.modes2] = \\\n",
    "            compl_mul2d(x_ft[:, :, -self.modes1:, :self.modes2], self.weights2)\n",
    "\n",
    "        #Return to physical space\n",
    "        x = torch.irfft(out_ft, 2, normalized=True, onesided=True, signal_sizes=( x.size(-2), x.size(-1)))\n",
    "        return x\n",
    "\n",
    "class SimpleBlock2d(nn.Module):\n",
    "    def __init__(self, modes1, modes2,  width):\n",
    "        super(SimpleBlock2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        The overall network. It contains 4 layers of the Fourier layer.\n",
    "        1. Lift the input to the desire channel dimension by self.fc0 .\n",
    "        2. 4 layers of the integral operators u' = (W + K)(u).\n",
    "            W defined by self.w; K defined by self.conv .\n",
    "        3. Project from the channel space to the output space by self.fc1 and self.fc2 .\n",
    "        \n",
    "        input: the solution of the coefficient function and locations (a(x, y), x, y)\n",
    "        input shape: (batchsize, x=s, y=s, c=3)\n",
    "        output: the solution \n",
    "        output shape: (batchsize, x=s, y=s, c=1)\n",
    "        \"\"\"\n",
    "\n",
    "        self.modes1 = modes1\n",
    "        self.modes2 = modes2\n",
    "        self.width = width\n",
    "        self.fc0 = nn.Linear(3, self.width) # input channel is 3: (a(x, y), x, y)\n",
    "\n",
    "        self.conv0 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv1 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv2 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.conv3 = SpectralConv2d(self.width, self.width, self.modes1, self.modes2)\n",
    "        self.w0 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w1 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w2 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.w3 = nn.Conv1d(self.width, self.width, 1)\n",
    "        self.bn0 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn1 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn2 = torch.nn.BatchNorm2d(self.width)\n",
    "        self.bn3 = torch.nn.BatchNorm2d(self.width)\n",
    "\n",
    "\n",
    "        self.fc1 = nn.Linear(self.width, 128)\n",
    "        self.fc2 = nn.Linear(128, 1)\n",
    "\n",
    "    def forward(self, x):\n",
    "        batchsize = x.shape[0]\n",
    "        size_x, size_y = x.shape[1], x.shape[2]\n",
    "\n",
    "        x = self.fc0(x)\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        x1 = self.conv0(x)\n",
    "        x2 = self.w0(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn0(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv1(x)\n",
    "        x2 = self.w1(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn1(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv2(x)\n",
    "        x2 = self.w2(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn2(x1 + x2)\n",
    "        x = F.relu(x)\n",
    "        x1 = self.conv3(x)\n",
    "        x2 = self.w3(x.view(batchsize, self.width, -1)).view(batchsize, self.width, size_x, size_y)\n",
    "        x = self.bn3(x1 + x2)\n",
    "\n",
    "\n",
    "        x = x.permute(0, 2, 3, 1)\n",
    "        x = self.fc1(x)\n",
    "        x = F.relu(x)\n",
    "        x = self.fc2(x)\n",
    "        return x\n",
    "\n",
    "class Net2d(nn.Module):\n",
    "    def __init__(self, modes, width):\n",
    "        super(Net2d, self).__init__()\n",
    "\n",
    "        \"\"\"\n",
    "        A wrapper function\n",
    "        \"\"\"\n",
    "\n",
    "        self.conv1 = SimpleBlock2d(modes, modes,  width)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        return x.squeeze()\n",
    "\n",
    "\n",
    "    def count_params(self):\n",
    "        c = 0\n",
    "        for p in self.parameters():\n",
    "            c += reduce(operator.mul, list(p.size()))\n",
    "\n",
    "        return c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "reader = utilities3.MatReader('data/piececonst_r421_N1024_smooth1.mat')\n",
    "x_train = reader.read_field('coeff')[:ntrain,::r,::r][:,:s,:s]\n",
    "y_train = reader.read_field('sol')[:ntrain,::r,::r][:,:s,:s]\n",
    "\n",
    "reader.load_file('data/piececonst_r421_N1024_smooth2.mat')\n",
    "x_test = reader.read_field('coeff')[:ntest,::r,::r][:,:s,:s]\n",
    "y_test = reader.read_field('sol')[:ntest,::r,::r][:,:s,:s]\n",
    "\n",
    "x_normalizer = utilities3.UnitGaussianNormalizer(x_train)\n",
    "x_train = x_normalizer.encode(x_train)\n",
    "x_test = x_normalizer.encode(x_test)\n",
    "\n",
    "y_normalizer = utilities3.UnitGaussianNormalizer(y_train)\n",
    "y_train = y_normalizer.encode(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is torch.Size([1000, 85, 85]) and the shape of y_train is torch.Size([1000, 85, 85])\n",
      "The shape of x_test is torch.Size([100, 85, 85]) and the shape of y_test is torch.Size([100, 85, 85])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of x_train is {x_train.shape} and the shape of y_train is {y_train.shape}')\n",
    "print(f'The shape of x_test is {x_test.shape} and the shape of y_test is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "grids = []\n",
    "grids.append(np.linspace(0, 1, s))\n",
    "grids.append(np.linspace(0, 1, s))\n",
    "grid = np.vstack([xx.ravel() for xx in np.meshgrid(*grids)]).T\n",
    "grid = grid.reshape(1,s,s,2)\n",
    "grid = torch.tensor(grid, dtype=torch.float)\n",
    "x_train = torch.cat([x_train.reshape(ntrain,s,s,1), grid.repeat(ntrain,1,1,1)], dim=3)\n",
    "x_test = torch.cat([x_test.reshape(ntest,s,s,1), grid.repeat(ntest,1,1,1)], dim=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The shape of x_train is torch.Size([1000, 85, 85, 3]) and the shape of y_train is torch.Size([1000, 85, 85])\n",
      "The shape of x_test is torch.Size([100, 85, 85, 3]) and the shape of y_test is torch.Size([100, 85, 85])\n"
     ]
    }
   ],
   "source": [
    "print(f'The shape of x_train is {x_train.shape} and the shape of y_train is {y_train.shape}')\n",
    "print(f'The shape of x_test is {x_test.shape} and the shape of y_test is {y_test.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_train, y_train), batch_size=batch_size, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=batch_size, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2368257\n"
     ]
    }
   ],
   "source": [
    "model = Net2d(modes, width).cuda()\n",
    "print(model.count_params())\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate, weight_decay=1e-4)\n",
    "\n",
    "myloss = utilities3.LpLoss(size_average=False)\n",
    "y_normalizer.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Saad.LAKES\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:34: UserWarning: The function torch.rfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.fft or torch.fft.rfft. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:590.)\n",
      "C:\\Users\\Saad.LAKES\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:42: UserWarning: The function torch.irfft is deprecated and will be removed in a future PyTorch release. Use the new torch.fft module functions, instead, by importing torch.fft and calling torch.fft.ifft or torch.fft.irfft. (Triggered internally at  ..\\aten\\src\\ATen\\native\\SpectralOps.cpp:602.)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 8.834618700000021 0.09111109149456025 0.05170911490917206\n",
      "1 2.6567812000000117 0.046579897165298464 0.03985527634620666\n",
      "2 2.6685765999999944 0.0412928404211998 0.03486134588718414\n",
      "3 2.743700799999999 0.033799034655094144 0.030667176842689513\n",
      "4 2.8604654999999752 0.03188143464922905 0.02923869848251343\n",
      "5 2.7338561000000254 0.02802168160676956 0.02725053608417511\n",
      "6 2.794751500000018 0.02625342744588852 0.025352153778076172\n",
      "7 2.6817557000000534 0.024682488292455673 0.021541155874729156\n",
      "8 2.7024353000000474 0.02538776686787605 0.024842909276485442\n",
      "9 2.6746226999999863 0.024641660302877427 0.023302284181118012\n",
      "10 2.751670899999965 0.024218062072992326 0.022085674107074738\n",
      "11 2.927811799999972 0.02431702482700348 0.021886611878871916\n",
      "12 2.855131999999969 0.02337981528043747 0.018514979779720307\n",
      "13 2.7650260000000344 0.0210777662396431 0.020594170689582823\n",
      "14 2.6921868000000018 0.02375592213869095 0.019794466495513915\n",
      "15 2.6900387000000023 0.022402075439691544 0.024126676321029664\n",
      "16 2.7176805000000286 0.024841046541929247 0.02434455007314682\n",
      "17 2.798921299999961 0.02590290144085884 0.019961881041526793\n",
      "18 2.833722900000055 0.02203519144654274 0.022949475347995758\n",
      "19 2.920078100000012 0.023921569138765336 0.018851576447486876\n",
      "20 2.7437863999999763 0.021238117784261705 0.023004892468452453\n",
      "21 2.6970991000000026 0.020113941311836244 0.02813808560371399\n",
      "22 2.682829400000003 0.021875584363937377 0.021121342182159424\n",
      "23 2.6775011999999947 0.019873356014490126 0.01787287026643753\n",
      "24 2.6827588000000446 0.023508060306310655 0.019320844411849974\n",
      "25 2.7445005999999807 0.0215105639398098 0.017274339199066163\n",
      "26 2.678431200000034 0.021043217301368714 0.01883538395166397\n",
      "27 2.6800518999999667 0.02010040780901909 0.020816493034362792\n",
      "28 2.6893097999999895 0.021297443121671675 0.017007109224796296\n",
      "29 2.6948491999999646 0.019944629818201064 0.016960175931453703\n",
      "30 2.6948095000000194 0.019613811537623406 0.018092955350875854\n",
      "31 2.727432199999953 0.01983400258421898 0.01668360471725464\n",
      "32 2.7970412999999894 0.022906068950891496 0.022339112758636474\n",
      "33 2.6888233999999898 0.020700648844242095 0.019847071468830108\n",
      "34 2.7432419000000436 0.02280786481499672 0.020416261553764345\n",
      "35 2.6988551999999686 0.01930325911939144 0.015869337916374206\n",
      "36 2.68148530000002 0.021105248540639877 0.018206111788749695\n",
      "37 2.9294237000000294 0.021060695827007293 0.018320094645023346\n",
      "38 2.8903832000000307 0.019863198056817053 0.01616565018892288\n"
     ]
    }
   ],
   "source": [
    "for ep in range(100):\n",
    "    model.train()\n",
    "    t1 = default_timer()\n",
    "    train_mse = 0\n",
    "    for x, y in train_loader:\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # loss = F.mse_loss(model(x).view(-1), y.view(-1), reduction='mean')\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(out)\n",
    "        y = y_normalizer.decode(y)\n",
    "        loss = myloss(out.view(batch_size,-1), y.view(batch_size,-1))\n",
    "        loss.backward()\n",
    "\n",
    "\n",
    "        optimizer.step()\n",
    "        train_mse += loss.item()\n",
    "\n",
    "    model.eval()\n",
    "    abs_err = 0.0\n",
    "    rel_err = 0.0\n",
    "    with torch.no_grad():\n",
    "        for x, y in test_loader:\n",
    "            x, y = x.cuda(), y.cuda()\n",
    "\n",
    "            out = model(x)\n",
    "            out = y_normalizer.decode(model(x))\n",
    "\n",
    "            rel_err += myloss(out.view(batch_size,-1), y.view(batch_size,-1)).item()\n",
    "\n",
    "    train_mse/= ntrain\n",
    "    abs_err /= ntest\n",
    "    rel_err /= ntest\n",
    "\n",
    "    t2 = default_timer()\n",
    "    print(ep, t2-t1, train_mse, rel_err)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = torch.zeros(y_test.shape)\n",
    "index = 0\n",
    "test_loader = torch.utils.data.DataLoader(torch.utils.data.TensorDataset(x_test, y_test), batch_size=1, shuffle=False)\n",
    "with torch.no_grad():\n",
    "    for x, y in test_loader:\n",
    "        test_l2 = 0\n",
    "        x, y = x.cuda(), y.cuda()\n",
    "\n",
    "        out = model(x)\n",
    "        out = y_normalizer.decode(model(x))\n",
    "        pred[index] = out\n",
    "        index = index + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
